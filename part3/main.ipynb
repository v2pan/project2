{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import Normalizer, ChiSqSelector\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, ArrayType\n",
    "from pyspark.ml.feature import Tokenizer, CountVectorizer\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import Normalizer, ChiSqSelector\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|            category|          reviewText|\n",
      "+--------------------+--------------------+\n",
      "|Patio_Lawn_and_Garde|This was a gift f...|\n",
      "|Patio_Lawn_and_Garde|This is a very ni...|\n",
      "|Patio_Lawn_and_Garde|The metal base wi...|\n",
      "|Patio_Lawn_and_Garde|For the most part...|\n",
      "|Patio_Lawn_and_Garde|This hose is supp...|\n",
      "|Patio_Lawn_and_Garde|This tool works v...|\n",
      "|Patio_Lawn_and_Garde|This product is a...|\n",
      "|Patio_Lawn_and_Garde|I was excited to ...|\n",
      "|Patio_Lawn_and_Garde|I purchased the L...|\n",
      "|Patio_Lawn_and_Garde|Never used a manu...|\n",
      "|Patio_Lawn_and_Garde|Good price. Good ...|\n",
      "|Patio_Lawn_and_Garde|I have owned the ...|\n",
      "|Patio_Lawn_and_Garde|I had \"won\" a sim...|\n",
      "|Patio_Lawn_and_Garde|The birds ate all...|\n",
      "|Patio_Lawn_and_Garde|Bought last summe...|\n",
      "|Patio_Lawn_and_Garde|I knew I had a mo...|\n",
      "|Patio_Lawn_and_Garde|I was a little wo...|\n",
      "|Patio_Lawn_and_Garde|I have used this ...|\n",
      "|Patio_Lawn_and_Garde|I actually do not...|\n",
      "|Patio_Lawn_and_Garde|Just what I  expe...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"SVMClassifier\").getOrCreate()\n",
    "\n",
    "# Define the file path\n",
    "file_path = \"reviews_devset.json\"\n",
    "\n",
    "# Read the JSON file into a DataFrame\n",
    "df = spark.read.json(file_path)\n",
    "\n",
    "# Show the DataFrame\n",
    "#df.show(truncate=True)\n",
    "\n",
    "df_sel=df.select('category','reviewText')\n",
    "df_sel.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|            category|          reviewText|     tokenized_words|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|Patio_Lawn_and_Garde|This was a gift f...|[This, was, a, gi...|\n",
      "|Patio_Lawn_and_Garde|This is a very ni...|[This, is, a, ver...|\n",
      "|Patio_Lawn_and_Garde|The metal base wi...|[The, metal, base...|\n",
      "|Patio_Lawn_and_Garde|For the most part...|[For, the, most, ...|\n",
      "|Patio_Lawn_and_Garde|This hose is supp...|[This, hose, is, ...|\n",
      "|Patio_Lawn_and_Garde|This tool works v...|[This, tool, work...|\n",
      "|Patio_Lawn_and_Garde|This product is a...|[This, product, i...|\n",
      "|Patio_Lawn_and_Garde|I was excited to ...|[I, was, excited,...|\n",
      "|Patio_Lawn_and_Garde|I purchased the L...|[I, purchased, th...|\n",
      "|Patio_Lawn_and_Garde|Never used a manu...|[Never, used, a, ...|\n",
      "|Patio_Lawn_and_Garde|Good price. Good ...|[Good, price, Goo...|\n",
      "|Patio_Lawn_and_Garde|I have owned the ...|[I, have, owned, ...|\n",
      "|Patio_Lawn_and_Garde|I had \"won\" a sim...|[I, had, won, a, ...|\n",
      "|Patio_Lawn_and_Garde|The birds ate all...|[The, birds, ate,...|\n",
      "|Patio_Lawn_and_Garde|Bought last summe...|[Bought, last, su...|\n",
      "|Patio_Lawn_and_Garde|I knew I had a mo...|[I, knew, I, had,...|\n",
      "|Patio_Lawn_and_Garde|I was a little wo...|[I, was, a, littl...|\n",
      "|Patio_Lawn_and_Garde|I have used this ...|[I, have, used, t...|\n",
      "|Patio_Lawn_and_Garde|I actually do not...|[I, actually, do,...|\n",
      "|Patio_Lawn_and_Garde|Just what I  expe...|[Just, what, I, e...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the text column using regular expressions\n",
    "tokenized_df = df_sel.withColumn(\"tokenized_words\", split(df[\"reviewText\"], r\"[ \\t\\d(){}\\[\\].!?,;:+=\\-_\\\"'`~#@&*%€$§\\\\/]+\"))\n",
    "tokenized_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|            category|          reviewText|     tokenized_words|        token_counts|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|Patio_Lawn_and_Garde|This was a gift f...|[This, was, a, gi...|(123970,[0,1,3,4,...|\n",
      "|Patio_Lawn_and_Garde|This is a very ni...|[This, is, a, ver...|(123970,[0,1,3,4,...|\n",
      "|Patio_Lawn_and_Garde|The metal base wi...|[The, metal, base...|(123970,[0,1,3,4,...|\n",
      "|Patio_Lawn_and_Garde|For the most part...|[For, the, most, ...|(123970,[0,1,2,3,...|\n",
      "|Patio_Lawn_and_Garde|This hose is supp...|[This, hose, is, ...|(123970,[0,1,2,3,...|\n",
      "|Patio_Lawn_and_Garde|This tool works v...|[This, tool, work...|(123970,[0,1,2,3,...|\n",
      "|Patio_Lawn_and_Garde|This product is a...|[This, product, i...|(123970,[0,1,3,4,...|\n",
      "|Patio_Lawn_and_Garde|I was excited to ...|[I, was, excited,...|(123970,[0,1,2,3,...|\n",
      "|Patio_Lawn_and_Garde|I purchased the L...|[I, purchased, th...|(123970,[0,1,2,3,...|\n",
      "|Patio_Lawn_and_Garde|Never used a manu...|[Never, used, a, ...|(123970,[0,1,3,4,...|\n",
      "|Patio_Lawn_and_Garde|Good price. Good ...|[Good, price, Goo...|(123970,[0,2,3,4,...|\n",
      "|Patio_Lawn_and_Garde|I have owned the ...|[I, have, owned, ...|(123970,[0,1,2,3,...|\n",
      "|Patio_Lawn_and_Garde|I had \"won\" a sim...|[I, had, won, a, ...|(123970,[0,1,2,3,...|\n",
      "|Patio_Lawn_and_Garde|The birds ate all...|[The, birds, ate,...|(123970,[0,2,3,4,...|\n",
      "|Patio_Lawn_and_Garde|Bought last summe...|[Bought, last, su...|(123970,[0,1,2,3,...|\n",
      "|Patio_Lawn_and_Garde|I knew I had a mo...|[I, knew, I, had,...|(123970,[0,1,2,3,...|\n",
      "|Patio_Lawn_and_Garde|I was a little wo...|[I, was, a, littl...|(123970,[0,1,2,3,...|\n",
      "|Patio_Lawn_and_Garde|I have used this ...|[I, have, used, t...|(123970,[0,1,2,4,...|\n",
      "|Patio_Lawn_and_Garde|I actually do not...|[I, actually, do,...|(123970,[0,1,2,3,...|\n",
      "|Patio_Lawn_and_Garde|Just what I  expe...|[Just, what, I, e...|(123970,[0,1,2,3,...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method _CountVectorizerParams.getMaxDF of CountVectorizerModel: uid=CountVectorizer_91c85590022d, vocabularySize=123970>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a CountVectorizer instance\n",
    "cv = CountVectorizer(inputCol='tokenized_words', outputCol='token_counts')\n",
    "\n",
    "# Apply the CountVectorizer to the tokenized DataFrame\n",
    "cv_model = cv.fit(tokenized_df)\n",
    "count_vectorized_df = cv_model.transform(tokenized_df)\n",
    "\n",
    "count_vectorized_df.show()\n",
    "\n",
    "#cv_model.getParam()\n",
    "\n",
    "# Get the vocabulary and token counts\n",
    "# vocabulary = cv_model.vocabulary\n",
    "# token_counts = cv_model.transform(tokenized_df).select('token_counts').collect()[0].token_counts\n",
    "\n",
    "# Convert token counts to a dictionary\n",
    "# token_count_pairs = dict(zip(vocabulary, token_counts))\n",
    "\n",
    "# # Print token-count pairs\n",
    "# for token, count in token_count_pairs.items():\n",
    "#     print(token, count)\n",
    "\n",
    "# Show the resulting DataFrame with token counts\n",
    "#count_vectorized_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, validation, and test sets\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.1\n",
    "seed = 42\n",
    "\n",
    "train_data, val_data, test_data = count_vectorized_df.randomSplit([train_ratio, val_ratio, test_ratio], seed=seed)\n",
    "\n",
    "# Set the feature column and label column\n",
    "feature_column = 'token_counts'\n",
    "label_column = 'label'\n",
    "\n",
    "# Create the SVM classifier\n",
    "svm = LinearSVC(featuresCol='selected_features')\n",
    "\n",
    "# Create the Normalizer for vector length normalization\n",
    "normalizer = Normalizer(inputCol=feature_column, outputCol='normalized_features')\n",
    "\n",
    "# Create the ChiSqSelector for feature selection\n",
    "selector = ChiSqSelector(numTopFeatures=2000, outputCol='category', labelCol=label_column)\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(stages=[normalizer, selector, svm])\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(svm.regParam, [0.1, 0.01, 0.001]) \\\n",
    "    .addGrid(svm.standardization, [True, False]) \\\n",
    "    .addGrid(svm.maxIter, [10, 100]) \\\n",
    "    .build()\n",
    "\n",
    "# Create the evaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=label_column, metricName='f1')\n",
    "\n",
    "# Create the TrainValidationSplit for parameter optimization\n",
    "tvs = TrainValidationSplit(estimator=pipeline,\n",
    "                           estimatorParamMaps=param_grid,\n",
    "                           evaluator=evaluator,\n",
    "                           trainRatio=train_ratio,\n",
    "                           seed=seed)\n",
    "\n",
    "# Train the model and select the best model using TrainValidationSplit\n",
    "model = tvs.fit(train_data)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "predictions = model.transform(test_data)\n",
    "f1_score = evaluator.evaluate(predictions)\n",
    "\n",
    "# Print the F1 score on the test set\n",
    "print(\"F1 Score on the test set: {:.4f}\".format(f1_score))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
